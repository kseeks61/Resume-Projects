{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fec507b-6b50-4453-8692-8bb148ccd78c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.9.0)\n",
      "Requirement already satisfied: qutip in /opt/conda/lib/python3.10/site-packages (5.2.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: scipy!=1.16.0,>=1.9 in /opt/conda/lib/python3.10/site-packages (from qutip) (1.15.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from qutip) (25.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy torch qutip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e86210d-b1c2-4147-918d-df1347e95c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from qutip import Qobj, ket2dm, basis  # only for generating initial qubit states\n",
    "import os\n",
    "import torch\n",
    "from google.cloud import storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55211663-bcd1-4a6a-9980-528b5740054c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_mixed_state_vectors(n_samples):\n",
    "    vectors = []\n",
    "    for _ in range(n_samples):\n",
    "        theta = np.arccos(2*np.random.rand() - 1)\n",
    "        phi = 2*np.pi*np.random.rand()\n",
    "        psi = np.cos(theta/2)*basis(2,0) + np.exp(1j*phi)*basis(2,1)\n",
    "        pure_dm = ket2dm(psi)\n",
    "        \n",
    "        p = np.random.rand()\n",
    "        if np.random.rand() > 0.5:\n",
    "            mixed_dm = p*pure_dm + (1-p)*ket2dm(basis(2,1))\n",
    "        else:\n",
    "            mixed_dm = p*pure_dm + (1-p)*ket2dm(basis(2,0))\n",
    "        \n",
    "        # Convert to 4-number real vector\n",
    "        vec = np.array([\n",
    "            mixed_dm[0,0].real,\n",
    "            mixed_dm[0,1].real,\n",
    "            mixed_dm[0,1].imag,\n",
    "            mixed_dm[1,1].real\n",
    "        ], dtype=np.float32)\n",
    "        vectors.append(vec)\n",
    "    return np.stack(vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6ffaf0c-a276-4b68-951b-00ae0b298b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sinusoidal_embedding(t, dim):\n",
    "    \"\"\"\n",
    "    t: tensor shape (B,1) or (B,) with integer timesteps (0..T-1) normalized to [0,1]\n",
    "    returns: (B, dim)\n",
    "    \"\"\"\n",
    "    if t.dim() == 1:\n",
    "        t = t.unsqueeze(-1)\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(-math.log(10000.0) * torch.arange(0, half, dtype=torch.float32) / half).to(t.device)\n",
    "    args = t.float() * freqs[None, :]\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "    if dim % 2 == 1:\n",
    "        emb = F.pad(emb, (0,1), \"constant\", 0.0)\n",
    "    return emb\n",
    "\n",
    "class QubitDenoiser(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, time_dim=32):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4 + time_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # t: tensor of shape (B,) or (B,1) with values in [0,1] (or normalized step index)\n",
    "        t_emb = sinusoidal_embedding(t, self.time_dim)\n",
    "        t_emb = self.time_mlp(t_emb)\n",
    "        inp = torch.cat([x, t_emb], dim=-1)\n",
    "        return self.net(inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1f9f02-a71e-49ea-84e2-624e379072c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward_diffusion_multistep(vector_data, original_vectors, steps=5, device='cpu'):\n",
    "    vector_data = vector_data.to(device)\n",
    "    original_vectors = original_vectors.to(device)\n",
    "    next_vectors = vector_data.clone()\n",
    "    N = next_vectors.shape[0]\n",
    "    \n",
    "    sqrt2_inv = 1.0 / torch.sqrt(torch.tensor(2.0, dtype=torch.float32, device=device))\n",
    "    U_clone = torch.tensor([[1,0,0,0],\n",
    "                            [0,sqrt2_inv,sqrt2_inv,0],\n",
    "                            [0,sqrt2_inv,-sqrt2_inv,0],\n",
    "                            [0,0,0,1]], dtype=torch.complex64, device=device)\n",
    "    U_clone_conj = U_clone.conj().T\n",
    "\n",
    "    fidelity_over_steps = []\n",
    "\n",
    "    for step in range(steps):\n",
    "        rho = torch.zeros((N,2,2), dtype=torch.complex64, device=device)\n",
    "        rho[:,0,0] = next_vectors[:,0]\n",
    "        rho[:,0,1] = next_vectors[:,1] + 1j*next_vectors[:,2]\n",
    "        rho[:,1,0] = next_vectors[:,1] - 1j*next_vectors[:,2]\n",
    "        rho[:,1,1] = next_vectors[:,3]\n",
    "\n",
    "        ancilla = torch.zeros((2,2), dtype=torch.complex64, device=device)\n",
    "        ancilla[0,0] = 1.0\n",
    "        rho_joint = torch.zeros((N,4,4), dtype=torch.complex64, device=device)\n",
    "        rho_joint[:,0:2,0:2] = rho * ancilla[0,0]\n",
    "\n",
    "        rho_cloned = torch.matmul(torch.matmul(U_clone.expand(N,4,4), rho_joint), U_clone_conj.expand(N,4,4))\n",
    "        clone1 = rho_cloned[:,0:2,0:2]\n",
    "        clone2 = rho_cloned[:,2:4,2:4]\n",
    "\n",
    "        weights = torch.rand(N,1,1, device=device)\n",
    "        next_rho = weights * clone1 + (1 - weights) * clone2\n",
    "\n",
    "        # Back to 4-number vectors\n",
    "        next_vectors[:,0] = next_rho[:,0,0].real\n",
    "        next_vectors[:,1] = next_rho[:,0,1].real\n",
    "        next_vectors[:,2] = next_rho[:,0,1].imag\n",
    "        next_vectors[:,3] = next_rho[:,1,1].real\n",
    "\n",
    "        # Fidelity proxy\n",
    "        rho_orig = torch.zeros((N,2,2), dtype=torch.complex64, device=device)\n",
    "        rho_orig[:,0,0] = original_vectors[:,0]\n",
    "        rho_orig[:,0,1] = original_vectors[:,1] + 1j*original_vectors[:,2]\n",
    "        rho_orig[:,1,0] = original_vectors[:,1] - 1j*original_vectors[:,2]\n",
    "        rho_orig[:,1,1] = original_vectors[:,3]\n",
    "\n",
    "        avg_fid = torch.mean(torch.real(torch.einsum('nij,nji->n', rho_orig, next_rho)))\n",
    "        fidelity_over_steps.append(avg_fid.item())\n",
    "\n",
    "    return next_vectors, fidelity_over_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec1170c4-d5d5-4d22-a893-db14a623290e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fidelity_loss(pred_vectors, target_vectors):\n",
    "    N = pred_vectors.shape[0]\n",
    "    rho_pred = torch.zeros((N,2,2), dtype=torch.complex64, device=pred_vectors.device)\n",
    "    rho_pred[:,0,0] = pred_vectors[:,0]\n",
    "    rho_pred[:,0,1] = pred_vectors[:,1] + 1j*pred_vectors[:,2]\n",
    "    rho_pred[:,1,0] = pred_vectors[:,1] - 1j*pred_vectors[:,2]\n",
    "    rho_pred[:,1,1] = pred_vectors[:,3]\n",
    "\n",
    "    rho_target = torch.zeros((N,2,2), dtype=torch.complex64, device=pred_vectors.device)\n",
    "    rho_target[:,0,0] = target_vectors[:,0]\n",
    "    rho_target[:,0,1] = target_vectors[:,1] + 1j*target_vectors[:,2]\n",
    "    rho_target[:,1,0] = target_vectors[:,1] - 1j*target_vectors[:,2]\n",
    "    rho_target[:,1,1] = target_vectors[:,3]\n",
    "\n",
    "    avg_fid = torch.mean(torch.real(torch.einsum('nij,nji->n', rho_target, rho_pred)))\n",
    "    return 1 - avg_fid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cff9b405-bc68-48bb-b102-d15f541db925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gcs(local_file, bucket_name, blob_name):\n",
    "    client = storage.Client()  # assumes your GCP credentials are set\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.upload_from_filename(local_file)\n",
    "    print(f\"Uploaded {local_file} to gs://{bucket_name}/{blob_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f36292d-072c-46d4-a4b6-8ce664c0b98e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_diffusion_with_gcs(model, vectors, bucket_name, gcs_folder=\"models\",\n",
    "                             epochs=5, batch_size=128, steps=5, lr=1e-3):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    dataset = torch.tensor(vectors, dtype=torch.float32)\n",
    "    N = dataset.shape[0]\n",
    "    split = int(0.8 * N)\n",
    "    train_data = dataset[:split]\n",
    "    test_data = dataset[split:]\n",
    "    \n",
    "    T = 5  # your noise steps\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        permutation = torch.randperm(train_data.shape[0])\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for i in range(0, train_data.shape[0], batch_size):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            idx = permutation[i:i+batch_size]\n",
    "            batch = train_data[idx].to(device)\n",
    "\n",
    "        # 1️⃣ Sample a random t (same t for whole batch is fine)\n",
    "            t_scalar = torch.randint(1, T + 1, (1,), device=device).item()\n",
    "\n",
    "        # 2️⃣ Apply t steps of forward diffusion\n",
    "            noisy_batch, _ = forward_diffusion_multistep(\n",
    "                batch, batch, steps=t_scalar, device=device\n",
    "            )\n",
    "\n",
    "        # 3️⃣ Model receives normalized timestep in [0,1]\n",
    "            t_input = torch.full(\n",
    "                (noisy_batch.size(0),),\n",
    "                float(t_scalar) / T,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "        # 4️⃣ Predict clean state x0\n",
    "            pred = model(noisy_batch, t_input)\n",
    "\n",
    "        # 5️⃣ Compute loss\n",
    "            loss = fidelity_loss(pred, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.6f}\")\n",
    "        # ----------------------\n",
    "        # Save checkpoint locally and upload to GCS\n",
    "        # ----------------------\n",
    "        local_checkpoint = f\"qubit_diffusion_epoch{epoch+1}.pt\"\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, local_checkpoint)\n",
    "\n",
    "        gcs_blob_name = os.path.join(gcs_folder, f\"qubit_diffusion_epoch{epoch+1}.pt\")\n",
    "        upload_to_gcs(local_checkpoint, bucket_name, gcs_blob_name)\n",
    "        os.remove(local_checkpoint)  # optional: remove local file to save space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84fa27c9-1aa1-4dc5-84d2-c2b4ac819ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def test_diffusion_model(model, test_vectors, steps=5, device=None, return_per_sample=False):\n",
    "    \"\"\"\n",
    "    Test a trained diffusion model on the test set.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    test_data = test_vectors.to(device)\n",
    "    T = steps  # same meaning as during training\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 1️⃣ Forward diffusion with T steps\n",
    "        noisy_test, _ = forward_diffusion_multistep(\n",
    "            test_data, test_data, steps=T, device=device\n",
    "        )\n",
    "        \n",
    "        # 2️⃣ Prepare timestep input (normalized to [0,1])\n",
    "        t_input = torch.full(\n",
    "            (noisy_test.size(0),),\n",
    "            float(T) / T,   # = 1.0 always for max-noise test\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # 3️⃣ Denoise using the time-conditioned model\n",
    "        pred_test = model(noisy_test, t_input)\n",
    "        \n",
    "        # 4️⃣ Convert predicted 4-vector → 2x2 density matrix\n",
    "        N = test_data.shape[0]\n",
    "        rho_pred = torch.zeros((N,2,2), dtype=torch.complex64, device=device)\n",
    "        rho_pred[:,0,0] = pred_test[:,0]\n",
    "        rho_pred[:,0,1] = pred_test[:,1] + 1j*pred_test[:,2]\n",
    "        rho_pred[:,1,0] = pred_test[:,1] - 1j*pred_test[:,2]\n",
    "        rho_pred[:,1,1] = pred_test[:,3]\n",
    "\n",
    "        # 5️⃣ Ground-truth density matrices\n",
    "        rho_target = torch.zeros((N,2,2), dtype=torch.complex64, device=device)\n",
    "        rho_target[:,0,0] = test_data[:,0]\n",
    "        rho_target[:,0,1] = test_data[:,1] + 1j*test_data[:,2]\n",
    "        rho_target[:,1,0] = test_data[:,1] - 1j*test_data[:,2]\n",
    "        rho_target[:,1,1] = test_data[:,3]\n",
    "\n",
    "        # 6️⃣ Fidelity-like overlap\n",
    "        per_sample_fidelity = torch.real(torch.einsum('nij,nji->n', rho_target, rho_pred))\n",
    "        avg_fidelity = torch.mean(per_sample_fidelity).item()\n",
    "\n",
    "    if return_per_sample:\n",
    "        return avg_fidelity, per_sample_fidelity.cpu().numpy()\n",
    "    else:\n",
    "        return avg_fidelity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c87b4cb9-1381-42f0-a651-d54fcd4ac179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1600, Test samples: 400\n",
      "Using device: cuda\n",
      "Epoch 1/10 - Loss: 9.698489\n",
      "Uploaded qubit_diffusion_epoch1.pt to gs://instr-cs795-fall25-hqin-1-kseek001/qubit_diffusion_checkpoints/qubit_diffusion_epoch1.pt\n",
      "Epoch 2/10 - Loss: -13.214288\n",
      "Uploaded qubit_diffusion_epoch2.pt to gs://instr-cs795-fall25-hqin-1-kseek001/qubit_diffusion_checkpoints/qubit_diffusion_epoch2.pt\n",
      "Epoch 3/10 - Loss: -134.561517\n",
      "Uploaded qubit_diffusion_epoch3.pt to gs://instr-cs795-fall25-hqin-1-kseek001/qubit_diffusion_checkpoints/qubit_diffusion_epoch3.pt\n",
      "Epoch 4/10 - Loss: -665.659897\n",
      "Uploaded qubit_diffusion_epoch4.pt to gs://instr-cs795-fall25-hqin-1-kseek001/qubit_diffusion_checkpoints/qubit_diffusion_epoch4.pt\n",
      "Epoch 5/10 - Loss: -2543.134743\n",
      "Uploaded qubit_diffusion_epoch5.pt to gs://instr-cs795-fall25-hqin-1-kseek001/qubit_diffusion_checkpoints/qubit_diffusion_epoch5.pt\n",
      "Epoch 6/10 - Loss: -8123.334503\n",
      "Uploaded qubit_diffusion_epoch6.pt to gs://instr-cs795-fall25-hqin-1-kseek001/qubit_diffusion_checkpoints/qubit_diffusion_epoch6.pt\n",
      "Epoch 7/10 - Loss: -22286.654907\n",
      "Uploaded qubit_diffusion_epoch7.pt to gs://instr-cs795-fall25-hqin-1-kseek001/qubit_diffusion_checkpoints/qubit_diffusion_epoch7.pt\n",
      "Epoch 8/10 - Loss: -54090.449951\n",
      "Uploaded qubit_diffusion_epoch8.pt to gs://instr-cs795-fall25-hqin-1-kseek001/qubit_diffusion_checkpoints/qubit_diffusion_epoch8.pt\n",
      "Epoch 9/10 - Loss: -120778.956543\n",
      "Uploaded qubit_diffusion_epoch9.pt to gs://instr-cs795-fall25-hqin-1-kseek001/qubit_diffusion_checkpoints/qubit_diffusion_epoch9.pt\n",
      "Epoch 10/10 - Loss: -246988.810547\n",
      "Uploaded qubit_diffusion_epoch10.pt to gs://instr-cs795-fall25-hqin-1-kseek001/qubit_diffusion_checkpoints/qubit_diffusion_epoch10.pt\n",
      "\n",
      "Final Test Set Average Fidelity: 27211.2969\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import torch\n",
    "    import os\n",
    "\n",
    "    # ----------------------\n",
    "    # 1️⃣ Generate dataset\n",
    "    # ----------------------\n",
    "    n_samples = 2000  # total qubit states\n",
    "    vectors = generate_mixed_state_vectors(n_samples)\n",
    "    dataset = torch.tensor(vectors, dtype=torch.float32)\n",
    "\n",
    "    # Split 80/20 train/test\n",
    "    split = int(0.8 * n_samples)\n",
    "    train_vectors = dataset[:split]\n",
    "    test_vectors = dataset[split:]\n",
    "\n",
    "    print(f\"Training samples: {train_vectors.shape[0]}, Test samples: {test_vectors.shape[0]}\")\n",
    "\n",
    "    # ----------------------\n",
    "    # 2️⃣ Initialize model\n",
    "    # ----------------------\n",
    "    model = QubitDenoiser()\n",
    "\n",
    "    # ----------------------\n",
    "    # 3️⃣ Define GCS bucket and folder\n",
    "    # ----------------------\n",
    "    bucket_name = \"instr-cs795-fall25-hqin-1-kseek001\" \n",
    "    gcs_folder = \"qubit_diffusion_checkpoints\"\n",
    "\n",
    "    # ----------------------\n",
    "    # 4️⃣ Train model with GCS checkpointing\n",
    "    # ----------------------\n",
    "    train_diffusion_with_gcs(\n",
    "        model=model,\n",
    "        vectors=vectors,\n",
    "        bucket_name=bucket_name,\n",
    "        gcs_folder=gcs_folder,\n",
    "        epochs=10,\n",
    "        batch_size=128,\n",
    "        steps=5,\n",
    "        lr=1e-3\n",
    "    )\n",
    "\n",
    "    # ----------------------\n",
    "    # 5️⃣ Test the trained model\n",
    "    # ----------------------\n",
    "    avg_fid, per_sample_fid = test_diffusion_model(\n",
    "        model=model,\n",
    "        test_vectors=test_vectors,\n",
    "        steps=5,\n",
    "        return_per_sample=True\n",
    "    )\n",
    "\n",
    "    print(f\"\\nFinal Test Set Average Fidelity: {avg_fid:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03940f93-a13f-4eb9-b090-99365beca6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
